# -*- coding: utf-8 -*-
"""task3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a9O8mr4EOIUJoVqHACkU1mYbHmPtdhhR
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv('bank.csv')

data.head()

data.shape

data.columns

data.dtypes

data.dtypes.value_counts()

data.info()

data.duplicated().sum()

data.isna().sum()

cat_col = data.select_dtypes(include='object').columns
print(cat_col)

cat_col = data.select_dtypes(exclude='object').columns
print(cat_col)

data.describe()

data.describe(include='object')

data.hist(figsize=(10,10),color='#cc5500')
plt.show()

for feature in cat_col:
    plt.figure(figsize=(5,5))
    sns.countplot(x=feature,data=data,palette='Wistia')
    plt.title('bar plot of {feature}')
    plt.xlabel(feature)
    plt.ylabel('count')
    plt.xticks(rotation=90)
    plt.show()

data.plot(kind='box',subplots=True,layout=(2,5),figsize=(20,10),color='#cc5500')
plt.show()

column = data[['age','campaign','duration']]
q1 = np.percentile(column,25)
q3 = np.percentile(column,75)
iqr = q3 - q1
lower_bound = q1 - 1.5*iqr
upper_bound = q3 + 1.5*iqr
data[['age','campaign','duration']] = column[(column>lower_bound)&(column<upper_bound)]

data.plot(kind='box',subplots=True,layout=(2,5),figsize=(20,10),color='#808000')
plt.show()

# Calculate the correlation matrix only for numerical columns
corr = data.select_dtypes(include=['number']).corr()
print(corr)

# Filter correlations and create a heatmap
corr = corr[abs(corr) > 0.90]
sns.heatmap(corr, annot=True, cmap='Set3', linewidths=0.2)
plt.show()

df = data.copy()

df.columns

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df_encoded  = df.apply(le.fit_transform)
df_encoded.head()

df_encoded['deposit'].value_counts()

x = df_encoded.drop('deposit',axis=1)
y = df_encoded['deposit']
print(x.shape)
print(y.shape)
print(type(x))
print(type(y))

from sklearn.model_selection import train_test_split
print(4119*0.25)

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=1)
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.metrics import accuracy_score,confusion_matrix,classification_report

def eval_model(y_test,y_pred):
  acc = accuracy_score(y_test,y_pred)
  cm = confusion_matrix(y_test,y_pred)
  cr = classification_report(y_test,y_pred)
  print('Accuracy Score : ',acc)
  print('Confusion Matrix : \n',cm)
  print('Classification Report : \n',cr)

def mscore(model):
  train_score = model.score(x_train,y_train)
  test_score = model.score(x_test,y_test)
  print('Train Score : ',model.score(x_train,y_train))
  print('Test Score : ',model.score(x_test,y_test))

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(criterion='gini',max_depth=5,min_samples_split=10)
dt.fit(x_train,y_train)

mscore(dt)

ypred_dt = dt.predict(x_test)
print(ypred_dt)

eval_model(y_test,ypred_dt)

from sklearn.tree import plot_tree

cn = ['no','yes']
fn = x_train.columns
print(cn)
print(fn)

plot_tree(dt,class_names=cn,filled=True)
plt.show()

dt1 = DecisionTreeClassifier(criterion='entropy',max_depth=5,min_samples_split=10)
dt1.fit(x_train,y_train)

mscore(dt1)

ypred_dt1 = dt1.predict(x_test)

eval_model(y_test,ypred_dt1)

plt.figure(figsize=(15,15))
plot_tree(dt1,class_names=cn,filled=True)
plt.show()

